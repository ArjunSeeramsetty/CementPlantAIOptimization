#!/bin/bash
# deploy_production.sh - Complete production deployment script for Cement Plant AI Digital Twin

set -e

echo "ðŸš€ Starting production deployment for Cement Plant AI Digital Twin"
echo "======================================================================"

# Configuration
export PROJECT_ID="cement-ai-opt-38517"
export REGION="us-central1"
export ZONE="us-central1-a"
export SERVICE_NAME="cement-plant-digital-twin"
export IMAGE_NAME="cement-plant-ai"
export SERVICE_ACCOUNT="cement-ops@cement-ai-opt-38517.iam.gserviceaccount.com"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING:${NC} $1"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1"
}

# Check prerequisites
check_prerequisites() {
    log "ðŸ” Checking deployment prerequisites..."
    
    # Check if gcloud is installed
    if ! command -v gcloud &> /dev/null; then
        error "gcloud CLI is not installed. Please install it first."
        exit 1
    fi
    
    # Check if docker is installed
    if ! command -v docker &> /dev/null; then
        error "Docker is not installed. Please install it first."
        exit 1
    fi
    
    # Check if terraform is installed
    if ! command -v terraform &> /dev/null; then
        warn "Terraform is not installed. Infrastructure deployment will be skipped."
        SKIP_TERRAFORM=true
    else
        SKIP_TERRAFORM=false
    fi
    
    # Check if kubectl is installed
    if ! command -v kubectl &> /dev/null; then
        warn "kubectl is not installed. GKE deployment will be skipped."
        SKIP_GKE=true
    else
        SKIP_GKE=false
    fi
    
    # Check service account key
    if [ ! -f ".secrets/cement-ops-key.json" ]; then
        error "Service account key not found at .secrets/cement-ops-key.json"
        exit 1
    fi
    
    log "âœ… Prerequisites check completed"
}

# Authenticate with Google Cloud
authenticate_gcp() {
    log "ðŸ” Authenticating with Google Cloud..."
    
    # Set service account key
    export GOOGLE_APPLICATION_CREDENTIALS="$(pwd)/.secrets/cement-ops-key.json"
    
    # Activate service account
    gcloud auth activate-service-account \
        --key-file="$GOOGLE_APPLICATION_CREDENTIALS"
    
    # Set project
    gcloud config set project $PROJECT_ID
    
    # Verify authentication
    gcloud auth list --filter=status:ACTIVE --format="value(account)"
    
    log "âœ… Google Cloud authentication completed"
}

# Deploy infrastructure with Terraform
deploy_infrastructure() {
    if [ "$SKIP_TERRAFORM" = true ]; then
        warn "Skipping Terraform infrastructure deployment"
        return
    fi
    
    log "ðŸ“¦ Deploying infrastructure with Terraform..."
    
    cd terraform/
    
    # Initialize Terraform
    terraform init
    
    # Plan deployment
    terraform plan -var="project_id=$PROJECT_ID" -var="region=$REGION" -var="zone=$ZONE"
    
    # Apply deployment
    terraform apply -auto-approve -var="project_id=$PROJECT_ID" -var="region=$REGION" -var="zone=$ZONE"
    
    # Get outputs
    CLUSTER_ENDPOINT=$(terraform output -raw cluster_endpoint)
    MODEL_ARTIFACTS_BUCKET=$(terraform output -raw model_artifacts_bucket)
    CLOUD_RUN_URL=$(terraform output -raw cloud_run_url)
    
    cd ..
    
    log "âœ… Infrastructure deployment completed"
    log "ðŸŒ Cluster endpoint: $CLUSTER_ENDPOINT"
    log "ðŸ“¦ Model artifacts bucket: $MODEL_ARTIFACTS_BUCKET"
    log "â˜ï¸ Cloud Run URL: $CLOUD_RUN_URL"
}

# Setup BigQuery ML models
setup_bigquery_ml() {
    log "ðŸ¤– Setting up BigQuery ML models..."
    
    # Run BigQuery ML setup script
    python scripts/setup_bigquery_ml.py
    
    if [ $? -eq 0 ]; then
        log "âœ… BigQuery ML models setup completed"
    else
        warn "BigQuery ML models setup failed, but continuing with deployment"
    fi
}

# Setup monitoring and alerting
setup_monitoring() {
    log "ðŸ“Š Setting up monitoring and alerting..."
    
    # Run monitoring setup script
    python scripts/setup_monitoring.py
    
    if [ $? -eq 0 ]; then
        log "âœ… Monitoring and alerting setup completed"
    else
        warn "Monitoring setup failed, but continuing with deployment"
    fi
}

# Build and push container image
build_and_push_image() {
    log "ðŸ³ Building and pushing container image..."
    
    # Build image
    docker build -t gcr.io/$PROJECT_ID/$IMAGE_NAME:latest .
    
    # Configure Docker for GCR
    gcloud auth configure-docker
    
    # Push image
    docker push gcr.io/$PROJECT_ID/$IMAGE_NAME:latest
    
    log "âœ… Container image built and pushed successfully"
}

# Deploy to Cloud Run
deploy_to_cloud_run() {
    log "â˜ï¸ Deploying to Cloud Run..."
    
    # Deploy service
    gcloud run deploy $SERVICE_NAME \
        --image gcr.io/$PROJECT_ID/$IMAGE_NAME:latest \
        --platform managed \
        --region $REGION \
        --allow-unauthenticated \
        --memory 4Gi \
        --cpu 2 \
        --max-instances 100 \
        --min-instances 2 \
        --timeout 300 \
        --concurrency 100 \
        --set-env-vars CEMENT_ENV=production,CEMENT_GCP_PROJECT=$PROJECT_ID,CEMENT_BQ_DATASET=cement_analytics \
        --service-account $SERVICE_ACCOUNT
    
    # Get service URL
    SERVICE_URL=$(gcloud run services describe $SERVICE_NAME --region=$REGION --format="value(status.url)")
    
    log "âœ… Cloud Run deployment completed"
    log "ðŸŒ Service URL: $SERVICE_URL"
}

# Deploy to GKE (optional)
deploy_to_gke() {
    if [ "$SKIP_GKE" = true ]; then
        warn "Skipping GKE deployment"
        return
    fi
    
    log "â˜¸ï¸ Deploying to GKE..."
    
    # Get cluster credentials
    gcloud container clusters get-credentials cement-plant-cluster --region=$REGION
    
    # Apply Kubernetes manifests
    kubectl apply -f k8s/cement-plant-deployment.yaml
    kubectl apply -f k8s/hpa-and-monitoring.yaml
    
    # Wait for deployment
    kubectl rollout status deployment/cement-plant-digital-twin
    
    # Get service info
    kubectl get services
    
    log "âœ… GKE deployment completed"
}

# Verify deployment
verify_deployment() {
    log "ðŸ§ª Verifying deployment..."
    
    # Get Cloud Run service URL
    SERVICE_URL=$(gcloud run services describe $SERVICE_NAME --region=$REGION --format="value(status.url)")
    
    # Test health endpoint
    log "Testing health endpoint..."
    if curl -f "$SERVICE_URL/health" > /dev/null 2>&1; then
        log "âœ… Health check passed"
    else
        warn "Health check failed, but service may still be starting"
    fi
    
    # Test API endpoint
    log "Testing API endpoint..."
    if curl -f "$SERVICE_URL/api/v1/status" > /dev/null 2>&1; then
        log "âœ… API endpoint accessible"
    else
        warn "API endpoint test failed"
    fi
    
    # Check Cloud Run service status
    gcloud run services describe $SERVICE_NAME --region=$REGION --format="value(status.conditions[0].status)"
    
    log "âœ… Deployment verification completed"
}

# Create deployment summary
create_deployment_summary() {
    log "ðŸ“‹ Creating deployment summary..."
    
    SERVICE_URL=$(gcloud run services describe $SERVICE_NAME --region=$REGION --format="value(status.url)")
    
    cat > deployment_summary.md << EOF
# ðŸ­ Cement Plant AI Digital Twin - Production Deployment Summary

## âœ… Deployment Status: SUCCESSFUL

**Deployment Date**: $(date)
**Project ID**: $PROJECT_ID
**Region**: $REGION
**Service Name**: $SERVICE_NAME

## ðŸŒ Service Endpoints

- **Cloud Run Service**: $SERVICE_URL
- **Health Check**: $SERVICE_URL/health
- **API Endpoint**: $SERVICE_URL/api/v1/
- **Monitoring Dashboard**: https://console.cloud.google.com/monitoring/overview?project=$PROJECT_ID
- **BigQuery Console**: https://console.cloud.google.com/bigquery?project=$PROJECT_ID

## ðŸ“Š Infrastructure Components

### âœ… Deployed Services
- **Cloud Run**: Auto-scaling serverless service (2-100 instances)
- **BigQuery**: Data warehouse with ML models
- **Cloud Monitoring**: Custom metrics and alerting
- **Cloud Logging**: Structured logging and compliance
- **Cloud Storage**: Model artifacts and data storage
- **Vertex AI**: Production Gemini integration

### âœ… ML Models
- **Quality Prediction Model**: Real-time free lime prediction
- **Energy Optimization Model**: Thermal energy efficiency optimization
- **Anomaly Detection Model**: Equipment health monitoring

### âœ… Monitoring & Alerting
- **Custom Metrics**: 6 critical cement plant KPIs
- **Alert Policies**: 3 production alert policies
- **Dashboard**: Real-time monitoring dashboard

## ðŸ”§ Configuration

### Environment Variables
- \`CEMENT_ENV=production\`
- \`CEMENT_GCP_PROJECT=$PROJECT_ID\`
- \`CEMENT_BQ_DATASET=cement_analytics\`

### Service Account
- **Account**: $SERVICE_ACCOUNT
- **Permissions**: AI Platform Admin, BigQuery Admin, Monitoring Admin, Storage Admin

### Resource Limits
- **Memory**: 4GB
- **CPU**: 2 cores
- **Timeout**: 300 seconds
- **Concurrency**: 100 requests

## ðŸš€ Next Steps

1. **Test the API**: Use the service URL to test all endpoints
2. **Configure Monitoring**: Set up custom dashboards in Cloud Monitoring
3. **Load Test**: Perform load testing to validate performance
4. **Data Integration**: Connect real plant data sources
5. **User Training**: Train plant operators on the new system

## ðŸ“ž Support

- **Documentation**: Check the README.md files in each component
- **Monitoring**: Use Cloud Monitoring for real-time system health
- **Logs**: Check Cloud Logging for detailed operation logs
- **Issues**: Create GitHub issues for any problems

---

**Deployment completed successfully! The Cement Plant AI Digital Twin is now running in production.** ðŸŽ‰
EOF

    log "âœ… Deployment summary created: deployment_summary.md"
}

# Main deployment function
main() {
    log "ðŸ­ CEMENT PLANT AI DIGITAL TWIN - PRODUCTION DEPLOYMENT"
    log "========================================================"
    
    # Check prerequisites
    check_prerequisites
    
    # Authenticate with GCP
    authenticate_gcp
    
    # Deploy infrastructure
    deploy_infrastructure
    
    # Setup BigQuery ML models
    setup_bigquery_ml
    
    # Setup monitoring
    setup_monitoring
    
    # Build and push image
    build_and_push_image
    
    # Deploy to Cloud Run
    deploy_to_cloud_run
    
    # Deploy to GKE (optional)
    deploy_to_gke
    
    # Verify deployment
    verify_deployment
    
    # Create summary
    create_deployment_summary
    
    log "ðŸŽ‰ PRODUCTION DEPLOYMENT COMPLETED SUCCESSFULLY!"
    log "ðŸŒ Service URL: $(gcloud run services describe $SERVICE_NAME --region=$REGION --format="value(status.url)")"
    log "ðŸ“Š Monitoring: https://console.cloud.google.com/monitoring/overview?project=$PROJECT_ID"
    log "ðŸ“ˆ BigQuery: https://console.cloud.google.com/bigquery?project=$PROJECT_ID"
}

# Run main function
main "$@"
